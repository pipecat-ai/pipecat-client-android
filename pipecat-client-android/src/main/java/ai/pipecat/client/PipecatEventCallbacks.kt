package ai.pipecat.client

import ai.pipecat.client.transport.MsgServerToClient
import ai.pipecat.client.types.BotLLMSearchResponseData
import ai.pipecat.client.types.BotReadyData
import ai.pipecat.client.types.LLMFunctionCallData
import ai.pipecat.client.types.MediaDeviceInfo
import ai.pipecat.client.types.Participant
import ai.pipecat.client.types.PipecatMetrics
import ai.pipecat.client.types.Tracks
import ai.pipecat.client.types.Transcript
import ai.pipecat.client.types.TransportState
import ai.pipecat.client.types.Value

/**
 * Callbacks invoked when changes occur in the session.
 */
@Suppress("unused")
abstract class PipecatEventCallbacks {

    /**
     * Invoked when the underlying transport has connected.
     */
    open fun onConnected() {}

    /**
     * Invoked when the underlying transport has disconnected.
     */
    open fun onDisconnected() {}

    /**
     * Invoked when the session state has changed.
     */
    open fun onTransportStateChanged(state: TransportState) {}

    /**
     * Invoked when the bot has connected to the session.
     */
    open fun onBotConnected(participant: Participant) {}

    /**
     * Invoked when the bot has indicated it is ready for commands.
     */
    open fun onBotReady(data: BotReadyData) {}

    /**
     * An error has occurred in the RTVI backend.
     */
    abstract fun onBackendError(message: String)

    /**
     * Invoked when the bot has disconnected from the session.
     */
    open fun onBotDisconnected(participant: Participant) {}

    /**
     * Invoked when a participant has joined the session.
     */
    open fun onParticipantJoined(participant: Participant) {}

    /**
     * Invoked when a participant has left the session.
     */
    open fun onParticipantLeft(participant: Participant) {}

    /**
     * Invoked when the list of available cameras has changed.
     */
    open fun onAvailableCamsUpdated(cams: List<MediaDeviceInfo>) {}

    /**
     * Invoked when the list of available microphones has updated.
     */
    open fun onAvailableMicsUpdated(mics: List<MediaDeviceInfo>) {}

    /**
     * Invoked regularly with the volume of the locally captured audio.
     */
    open fun onUserAudioLevel(level: Float) {}

    /**
     * Invoked regularly with the audio volume of each remote participant.
     */
    open fun onRemoteAudioLevel(level: Float, participant: Participant) {}

    /**
     * Invoked when the bot starts talking.
     */
    open fun onBotStartedSpeaking() {}

    /**
     * Invoked when the bot stops talking.
     */
    open fun onBotStoppedSpeaking() {}

    /**
     * Invoked when the local user starts talking.
     */
    open fun onUserStartedSpeaking() {}

    /**
     * Invoked when the local user stops talking.
     */
    open fun onUserStoppedSpeaking() {}

    /**
     * Invoked when session metrics are received.
     */
    open fun onMetrics(data: PipecatMetrics) {}

    /**
     * Invoked when user transcript data is available.
     */
    open fun onUserTranscript(data: Transcript) {}

    /**
     * Invoked when bot transcript data is available.
     */
    open fun onBotTranscript(text: String) {}

    /**
     * Invoked when a message from the backend is received which was not handled
     * by the PipecatClient.
     */
    open fun onGenericMessage(msg: MsgServerToClient) {}

    /**
     * Invoked when the state of the input devices changes.
     */
    open fun onInputsUpdated(camera: Boolean, mic: Boolean) {}

    /**
     * Invoked when the set of available cam/mic tracks changes.
     */
    open fun onTracksUpdated(tracks: Tracks) {}

    /**
     * Invoked when text is generated by the bot LLM.
     */
    open fun onBotLLMText(data: MsgServerToClient.Data.BotLLMTextData) {}

    /**
     * Invoked when text is spoken by the bot.
     */
    open fun onBotTTSText(data: MsgServerToClient.Data.BotTTSTextData) {}

    /**
     * Invoked when the bot starts generating LLM text.
     */
    open fun onBotLLMStarted() {}

    /**
     * Invoked when the bot stops generating LLM text.
     */
    open fun onBotLLMStopped() {}

    /**
     * Invoked when the bot starts generating TTS output.
     */
    open fun onBotTTSStarted() {}

    /**
     * Invoked when the bot stops generating TTS output.
     */
    open fun onBotTTSStopped() {}

    /**
     * Invoked when we receive a server message from the bot.
     */
    open fun onServerMessage(data: Value) {}

    /**
     * Invoked when the bot performs a web search.
     */
    open fun onBotLLMSearchResponse(data: BotLLMSearchResponseData) {}

    /**
     * Invoked when the bot makes a function call request to the client. The client must
     * respond by invoking `onResult`.
     */
    open fun onLLMFunctionCall(
        functionCallData: LLMFunctionCallData,
        onResult: (Value) -> Unit
    ) {
        onResult(Value.Null)
    }
}
